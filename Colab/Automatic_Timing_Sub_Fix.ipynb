{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndryOut/Automatic-Timing-Sub-Fix/blob/main/Automatic_Timing_Sub_Fix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PkbHT2pNgeBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Fase 1\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", package])\n",
        "\n",
        "install('pysrt')\n",
        "install('pyass')\n",
        "install('ipywidgets')\n",
        "\n",
        "import pysrt\n",
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "def load_file():\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        return filename\n",
        "\n",
        "def read_ass_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8-sig') as file:\n",
        "        content = file.readlines()\n",
        "    return content\n",
        "\n",
        "def find_top_alignments(styles, dialogue):\n",
        "    top_alignments = ['7', '8', '9']\n",
        "    top_styles = []\n",
        "    alignment_index = None\n",
        "    for line in styles:\n",
        "        if line.startswith('Format:'):\n",
        "            format_parts = [x.strip() for x in line.split(':')[1].split(',')]\n",
        "            if 'Alignment' in format_parts:\n",
        "                alignment_index = format_parts.index('Alignment')\n",
        "        elif line.startswith('Style:') and alignment_index is not None:\n",
        "            style_parts = line.split(',')\n",
        "            alignment = style_parts[alignment_index].strip()\n",
        "            if alignment in top_alignments:\n",
        "                style_name = style_parts[0].replace('Style:', '').strip()\n",
        "                top_styles.append(style_name)\n",
        "\n",
        "    if not top_styles or not any(line.split(',')[3].strip() in top_styles for line in dialogue):\n",
        "        top_styles = find_alignments_in_dialogue(dialogue, top_alignments)\n",
        "\n",
        "    return top_styles\n",
        "\n",
        "def find_alignments_in_dialogue(dialogue, top_alignments):\n",
        "    dialogue_with_alignments = []\n",
        "    for line in dialogue:\n",
        "        if any(alignment in line for alignment in top_alignments) or '{\\\\an8}' in line:\n",
        "            dialogue_with_alignments.append(line)\n",
        "    return dialogue_with_alignments\n",
        "\n",
        "def filter_dialogue_by_style(dialogue, top_styles):\n",
        "    filtered_dialogue = [line for line in dialogue if line.split(',')[3].strip() in top_styles or '{\\\\an8}' in line]\n",
        "    discarded_dialogue = [line for line in dialogue if line.split(',')[3].strip() not in top_styles and '{\\\\an8}' not in line]\n",
        "    return filtered_dialogue, discarded_dialogue\n",
        "\n",
        "def write_ass_file(header, dialogue, format_line, file_path):\n",
        "    with open(file_path, 'w', encoding='utf-8') as file:\n",
        "        file.writelines(header + [format_line] + dialogue)\n",
        "\n",
        "def write_srt_file(discarded_dialogue, file_path):\n",
        "    subs = pysrt.SubRipFile()\n",
        "    for idx, line in enumerate(discarded_dialogue):\n",
        "        parts = line.split(',')\n",
        "        start = parts[1].replace('.', ',')\n",
        "        end = parts[2].replace('.', ',')\n",
        "        text = ','.join(parts[9:]).strip()\n",
        "        sub = pysrt.SubRipItem(index=idx+1, start=start, end=end, text=text)\n",
        "        subs.append(sub)\n",
        "    subs.save(file_path, encoding='utf-8')\n",
        "\n",
        "def process_ass_file(file_path):\n",
        "    lines = read_ass_file(file_path)\n",
        "    header_section = []\n",
        "    dialogue_section = []\n",
        "    capture_dialogue = False\n",
        "    capture_styles = False\n",
        "    styles_section = []\n",
        "    format_line_events = \"\"\n",
        "    format_line_styles = \"\"\n",
        "    for line in lines:\n",
        "        if line.startswith('[V4+ Styles]'):\n",
        "            capture_styles = True\n",
        "            header_section.append(line)\n",
        "            continue\n",
        "        if line.startswith('[Events]'):\n",
        "            capture_styles = False\n",
        "            capture_dialogue = True\n",
        "            header_section.append(line)\n",
        "            continue\n",
        "        if capture_dialogue and line.startswith('Dialogue:'):\n",
        "            dialogue_section.append(line)\n",
        "        elif not capture_dialogue:\n",
        "            header_section.append(line)\n",
        "        if capture_styles and line.startswith('Format:'):\n",
        "            format_line_styles = line\n",
        "        if not capture_styles and line.startswith('Format:'):\n",
        "            format_line_events = line\n",
        "        if capture_styles:\n",
        "            styles_section.append(line)\n",
        "\n",
        "    top_styles = find_top_alignments(styles_section, dialogue_section)\n",
        "    filtered_dialogue, discarded_dialogue = filter_dialogue_by_style(dialogue_section, top_styles)\n",
        "\n",
        "    return header_section, filtered_dialogue, discarded_dialogue, format_line_events\n",
        "\n",
        "def process_srt_file(file_path):\n",
        "    subs = pysrt.open(file_path, encoding='utf-8')\n",
        "    an8_subs = pysrt.SubRipFile()\n",
        "    discarded_subs = pysrt.SubRipFile()\n",
        "\n",
        "    for sub in subs:\n",
        "        if '{\\\\an8}' in sub.text:\n",
        "            an8_subs.append(sub)\n",
        "        else:\n",
        "            discarded_subs.append(sub)\n",
        "\n",
        "    an8_subs.save('On Top.srt', encoding='utf-8')\n",
        "    discarded_subs.save('Sub.srt', encoding='utf-8')\n",
        "\n",
        "    print('Sottotitoli processati e salvati in output.srt')\n",
        "    print('Righe scartate salvate in Sub.srt')\n",
        "\n",
        "def on_button_yes_clicked(b):\n",
        "    print(\"Per una precisione maggiore e per evitare conflitti nei prossimi script, dovrai prima togliere i cartelli dai sub.\")\n",
        "    print(\"Una volta tolti, riavvia lo script.\")\n",
        "\n",
        "def on_button_no_clicked(b):\n",
        "    input_file_path = load_file()\n",
        "\n",
        "    if input_file_path.endswith('.srt'):\n",
        "        process_srt_file(input_file_path)\n",
        "    else:\n",
        "        output_ass_file_path = 'On Top.ass'\n",
        "        output_srt_file_path = 'Sub.srt'\n",
        "        header, dialogue, discarded_dialogue, format_line = process_ass_file(input_file_path)\n",
        "        write_ass_file(header, dialogue, format_line, output_ass_file_path)\n",
        "        write_srt_file(discarded_dialogue, output_srt_file_path)\n",
        "        print(f'Sottotitoli processati e salvati in {output_ass_file_path}')\n",
        "        print(f'Righe scartate salvate in {output_srt_file_path}')\n",
        "\n",
        "def ask_about_signs():\n",
        "    button_yes = widgets.Button(description=\"Sì\")\n",
        "    button_no = widgets.Button(description=\"No\")\n",
        "    button_yes.on_click(on_button_yes_clicked)\n",
        "    button_no.on_click(on_button_no_clicked)\n",
        "    display(widgets.HBox([widgets.Label(\"I sub che stai caricando hanno i cartelli?\"), button_yes, button_no]))\n",
        "\n",
        "def main():\n",
        "    ask_about_signs()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "2Wxdagmi5vH_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Fase 2\n",
        "!pip install pysrt pydub librosa\n",
        "\n",
        "import pysrt\n",
        "from pydub import AudioSegment\n",
        "import librosa\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "# Funzione per convertire i millisecondi in SubRipTime\n",
        "def milliseconds_to_subrip_time(milliseconds):\n",
        "    hours = int(milliseconds // 3600000)\n",
        "    minutes = int((milliseconds % 3600000) // 60000)\n",
        "    seconds = int((milliseconds % 60000) // 1000)\n",
        "    milliseconds = int(milliseconds % 1000)\n",
        "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=seconds, milliseconds=milliseconds)\n",
        "\n",
        "# Funzione per rilevare i segmenti audio con Pydub e Librosa\n",
        "def get_audio_segments(audio_file, silence_threshold=320):\n",
        "    # Carica l'audio con Pydub\n",
        "    audio = AudioSegment.from_file(audio_file)\n",
        "    audio.export(\"temp.wav\", format=\"wav\")\n",
        "\n",
        "    # Carica l'audio con Librosa\n",
        "    y, sr = librosa.load(\"temp.wav\", sr=None)\n",
        "\n",
        "    # Rileva i segmenti non silenziosi\n",
        "    intervals = librosa.effects.split(y, top_db=20)\n",
        "\n",
        "    # Converte i segmenti in millisecondi\n",
        "    segments = []\n",
        "    for start, end in intervals:\n",
        "        segments.append((start / sr * 1000, end / sr * 1000))\n",
        "\n",
        "    return segments\n",
        "\n",
        "# Funzione per rilevare i picchi audio per aggiustare i time stamps\n",
        "def adjust_timestamps_based_on_peaks(subs, audio_file):\n",
        "    audio_segments = get_audio_segments(audio_file)\n",
        "    for sub in subs:\n",
        "        start_ms = sub.start.ordinal\n",
        "        end_ms = sub.end.ordinal\n",
        "\n",
        "        # Trova il primo picco audio dopo l'inizio del time stamp\n",
        "        for segment_start, segment_end in audio_segments:\n",
        "            if segment_start >= start_ms:\n",
        "                # Se il primo picco audio rilevato supera il range massimo di 0,300 secondi, cerca un altro picco più vicino\n",
        "                if segment_start - start_ms > 550:\n",
        "                    found = False\n",
        "                    for closer_segment_start, closer_segment_end in audio_segments:\n",
        "                        if start_ms <= closer_segment_start <= start_ms + 500:\n",
        "                            sub.start = milliseconds_to_subrip_time(closer_segment_start)\n",
        "                            found = True\n",
        "                            break\n",
        "                    if not found:\n",
        "                        sub.start = milliseconds_to_subrip_time(start_ms)\n",
        "                else:\n",
        "                    sub.start = milliseconds_to_subrip_time(segment_start)\n",
        "                break\n",
        "\n",
        "        # Se il time stamp finale della riga attuale è già su un picco audio, lo cerca dopo il time stamp finale\n",
        "        is_on_peak = False\n",
        "        for segment_start, segment_end in audio_segments:\n",
        "            if segment_start <= end_ms <= segment_end:\n",
        "                is_on_peak = True\n",
        "                break\n",
        "\n",
        "        if is_on_peak:\n",
        "            # Cerca un picco audio dopo il time stamp finale nel range di 0,150 secondi\n",
        "            found = False\n",
        "            for segment_start, segment_end in audio_segments:\n",
        "                if end_ms <= segment_start <= end_ms + 150:\n",
        "                    sub.end = milliseconds_to_subrip_time(segment_start)\n",
        "                    found = True\n",
        "                    break\n",
        "            if not found:\n",
        "                sub.end = milliseconds_to_subrip_time(end_ms)\n",
        "\n",
        "        # Trova l'ultimo picco audio prima della fine del time stamp\n",
        "        max_ranges = [300, 400]\n",
        "        for max_range in max_ranges:\n",
        "            found = False\n",
        "            for segment_start, segment_end in reversed(audio_segments):\n",
        "                if segment_end <= end_ms and segment_start >= start_ms:\n",
        "                    if end_ms - segment_end <= max_range:\n",
        "                        sub.end = milliseconds_to_subrip_time(segment_end)\n",
        "                        found = True\n",
        "                        break\n",
        "            if found:\n",
        "                break\n",
        "\n",
        "        # Se il picco audio rilevato è troppo lontano, lo cerca di nuovo\n",
        "        if end_ms - sub.end.ordinal > 410:\n",
        "            for segment_start, segment_end in audio_segments:\n",
        "                if segment_end <= end_ms and segment_start >= start_ms:\n",
        "                    if end_ms - segment_end <= 300:\n",
        "                        sub.end = milliseconds_to_subrip_time(segment_end)\n",
        "                        break\n",
        "            else:\n",
        "                sub.end = milliseconds_to_subrip_time(end_ms)\n",
        "\n",
        "    return subs\n",
        "\n",
        "# Funzione per aggiungere lead-in e lead-out ai segmenti\n",
        "def add_lead_in_out(segments, original_subs, lead_in=200, lead_out=500):\n",
        "    adjusted_segments = []\n",
        "    for i, (start, end) in enumerate(segments):\n",
        "        original_start_ms = original_subs[i].start.ordinal\n",
        "        if start == original_start_ms:\n",
        "            new_start = start  # Non aggiungere lead-in se è uguale al time stamp originale\n",
        "        else:\n",
        "            new_start = max(0, start - lead_in)  # Aggiungi lead-in altrimenti\n",
        "        new_end = end + lead_out  # Aggiungi lead-out a tutto\n",
        "        adjusted_segments.append((new_start, new_end))\n",
        "    return adjusted_segments\n",
        "\n",
        "# Funzione per collegare segmenti senza overlap con spazio di 0,000 secondi\n",
        "def adjust_segments_for_overlap(segments, max_lead_out=800, lead_in=200, max_lead_in=270, lead_out=500):\n",
        "    adjusted_segments = []\n",
        "    for i in range(len(segments) - 1):\n",
        "        start, end = segments[i]\n",
        "        next_start, next_end = segments[i + 1]\n",
        "\n",
        "        if (next_start - end) <= max_lead_out:\n",
        "            if (next_start - end) > lead_out:\n",
        "                remaining_time = next_start - end - lead_out\n",
        "                end = next_start - remaining_time  # collega con spazio di 0,000 secondi\n",
        "            else:\n",
        "                end = next_start  # collega con spazio di 0,000 secondi\n",
        "        else:\n",
        "            if (next_start - end) > lead_in and (next_start - end) < max_lead_in:\n",
        "                end = next_start - lead_in\n",
        "\n",
        "        adjusted_segments.append((start, end))\n",
        "\n",
        "    adjusted_segments.append(segments[-1])\n",
        "    return adjusted_segments\n",
        "\n",
        "# Chiede di caricare prima un file audio e dopo un file SRT\n",
        "uploaded_audio = files.upload()\n",
        "audio_file = list(uploaded_audio.keys())[0]\n",
        "\n",
        "uploaded_srt = files.upload()\n",
        "srt_file = list(uploaded_srt.keys())[0]\n",
        "\n",
        "# Carica il file SRT originale\n",
        "subs = pysrt.open(srt_file, encoding='utf-8')\n",
        "original_subs = pysrt.open(srt_file, encoding='utf-8')  # Fai una copia del file SRT originale\n",
        "\n",
        "# Aggiusta i time stamps delle righe in base ai picchi audio rilevati\n",
        "subs = adjust_timestamps_based_on_peaks(subs, audio_file)\n",
        "\n",
        "# Ottieni i segmenti audio con Pydub e Librosa\n",
        "audio_segments = get_audio_segments(audio_file)\n",
        "\n",
        "# Non unisce i segmenti, mantiene solo quelli esistenti\n",
        "final_segments = [(sub.start.ordinal, sub.end.ordinal) for sub in subs]\n",
        "\n",
        "# Aggiunge lead-in e lead-out ai segmenti\n",
        "adjusted_segments = add_lead_in_out(final_segments, original_subs)\n",
        "\n",
        "# Regola i segmenti per evitare overlap e collegarli con spazio di 0,000 secondi\n",
        "adjusted_segments = adjust_segments_for_overlap(adjusted_segments)\n",
        "\n",
        "# Crea il file SRT basato sui segmenti finali e mantiene il testo originale\n",
        "for sub, (start, end) in zip(subs, adjusted_segments):\n",
        "    sub.start = milliseconds_to_subrip_time(start)\n",
        "    sub.end = milliseconds_to_subrip_time(end)\n",
        "\n",
        "# Salva il file SRT finale\n",
        "output_file = 'adjusted_' + srt_file\n",
        "subs.save(output_file, encoding='utf-8')\n",
        "\n",
        "print(f\"File SRT salvato come {output_file}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LwOW3AnE5-IM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Fase 3\n",
        "!pip install scenedetect[opencv] pysrt\n",
        "\n",
        "from scenedetect import open_video, SceneManager, FrameTimecode\n",
        "from scenedetect.detectors import AdaptiveDetector, ContentDetector\n",
        "import pysrt\n",
        "\n",
        "# Funzione per esportare i risultati in formato SRT con precisione al millisecondo\n",
        "def export_srt(scene_list, output_path='scene_timestamps.srt'):\n",
        "    def seconds_to_timecode(seconds):\n",
        "        hrs = int(seconds // 3600)\n",
        "        mins = int((seconds % 3600) // 60)\n",
        "        secs = int(seconds % 60)\n",
        "        millis = int((seconds % 1) * 1000)\n",
        "        return f\"{hrs:02}:{mins:02}:{secs:02},{millis:03}\"\n",
        "\n",
        "    with open(output_path, 'w') as f:\n",
        "        for i, scene in enumerate(scene_list):\n",
        "            start_time = scene[0].get_seconds()\n",
        "            end_time = scene[1].get_seconds() - 0.001  # Sottrai 1 millisecondo per evitare sovrapposizioni\n",
        "\n",
        "            start_timecode = seconds_to_timecode(start_time)\n",
        "            end_timecode = seconds_to_timecode(end_time)\n",
        "\n",
        "            f.write(f\"{i+1}\\n\")\n",
        "            f.write(f\"{start_timecode} --> {end_timecode}\\n\")\n",
        "            f.write(f\"Scene {i+1}\\n\\n\")\n",
        "\n",
        "# Funzione per calcolare la discrepanza costante\n",
        "def calculate_discrepancy(scene_list, srt_path):\n",
        "    # Carica il file SRT esistente\n",
        "    subs = pysrt.open(srt_path, encoding='utf-8')\n",
        "\n",
        "    # Calcola la discrepanza tra i cambi scena e i timecode dei sottotitoli\n",
        "    discrepancies = []\n",
        "    count = min(len(scene_list), len(subs))\n",
        "    for i in range(count):\n",
        "        scene_start = scene_list[i][0].get_seconds()\n",
        "        subtitle_start = subs[i].start.ordinal / 1000\n",
        "        discrepancy = scene_start - subtitle_start\n",
        "        discrepancies.append(discrepancy)\n",
        "\n",
        "    # Ritorna la discrepanza media\n",
        "    return sum(discrepancies) / len(discrepancies)\n",
        "\n",
        "# Funzione per trovare l'offset più vicino ai valori predefiniti\n",
        "def find_closest_offset(discrepancy, possible_offsets):\n",
        "    closest_offset = min(possible_offsets, key=lambda x: abs(x - discrepancy))\n",
        "    return closest_offset\n",
        "\n",
        "# Funzione per applicare un offset globale al file SRT\n",
        "def apply_global_offset_to_srt(input_path, output_path, offset):\n",
        "    def apply_offset(timecode, offset):\n",
        "        timecode.ordinal += int(offset * 1000)  # Converte i secondi in millisecondi\n",
        "        return timecode\n",
        "\n",
        "    # Carica il file SRT esistente\n",
        "    subs = pysrt.open(input_path, encoding='utf-8')\n",
        "\n",
        "    # Applica l'offset ai timecode di inizio e fine\n",
        "    for sub in subs:\n",
        "        sub.start = apply_offset(sub.start, offset)\n",
        "        sub.end = apply_offset(sub.end, offset)\n",
        "\n",
        "    # Salva il file SRT con i timecode modificati\n",
        "    subs.save(output_path, encoding='utf-8')\n",
        "\n",
        "# Caricamento del Video\n",
        "video_path = '/content/Ep.mkv'\n",
        "\n",
        "# Verifica se il file video è stato caricato correttamente\n",
        "if not video_path:\n",
        "    raise FileNotFoundError(\"Il file video non è stato trovato.\")\n",
        "\n",
        "# Caricamento del Video\n",
        "video_manager = open_video(video_path)\n",
        "\n",
        "# Crea un SceneManager con AdaptiveDetector e ContentDetector\n",
        "scene_manager = SceneManager()\n",
        "adaptive_detector = AdaptiveDetector(adaptive_threshold=19)\n",
        "content_detector = ContentDetector(threshold=19)\n",
        "scene_manager.add_detector(adaptive_detector)\n",
        "scene_manager.add_detector(content_detector)\n",
        "\n",
        "# Rileva le scene per tutta la durata del video\n",
        "scene_manager.detect_scenes(video_manager)\n",
        "scene_list = scene_manager.get_scene_list()\n",
        "\n",
        "# Defininisce il percorso del file SRT di output\n",
        "srt_output_path = 'scene_timestamps.srt'\n",
        "\n",
        "# Esportare i risultati in formato SRT\n",
        "export_srt(scene_list, output_path=srt_output_path)\n",
        "\n",
        "# Calcola la discrepanza costante in base ai cambi scena e ai sottotitoli\n",
        "discrepancy = calculate_discrepancy(scene_list, srt_output_path)\n",
        "\n",
        "# Definisce i possibili offset negativi in secondi\n",
        "possible_offsets = [-0.011, -0.021, -0.031, -0.041]\n",
        "\n",
        "# Trova l'offset più vicino\n",
        "best_offset = find_closest_offset(discrepancy, possible_offsets)\n",
        "\n",
        "# Applica l'offset globale al file SRT\n",
        "apply_global_offset_to_srt(srt_output_path, 'scene_timestamps_adjusted.srt', best_offset)\n",
        "\n",
        "print(f\"Scene rilevate: {len(scene_list)}\")\n",
        "for i, scene in enumerate(scene_list):\n",
        "    print(f'Scena {i+1}: Inizio: {scene[0].get_timecode()}, Fine: {scene[1].get_timecode()}')\n",
        "\n",
        "print(f'File SRT con offset globale applicato creato con successo: scene_timestamps_adjusted.srt')\n",
        "print(f'Offset applicato: {best_offset:.3f} secondi')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "E_fieDNM6hek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Fase 4\n",
        "!pip install pysrt pydub librosa\n",
        "\n",
        "# Importa le librerie\n",
        "import pysrt\n",
        "from pydub import AudioSegment\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# Funzione per convertire i millisecondi in SubRip Time\n",
        "def milliseconds_to_subrip_time(milliseconds):\n",
        "    hours = int(milliseconds // 3600000)\n",
        "    minutes = int((milliseconds % 3600000) // 60000)\n",
        "    seconds = int((milliseconds % 60000) // 1000)\n",
        "    milliseconds = int(milliseconds % 1000)\n",
        "    return pysrt.SubRipTime(hours=hours, minutes=minutes, seconds=seconds, milliseconds=milliseconds)\n",
        "\n",
        "# Funzione per rilevare i picchi audio\n",
        "def get_audio_peaks(audio_file):\n",
        "    y, sr = librosa.load(audio_file)\n",
        "    onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
        "    peaks = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr, backtrack=True)\n",
        "    peak_times = librosa.frames_to_time(peaks, sr=sr)\n",
        "    return peak_times\n",
        "\n",
        "# Funzione per rilevare cambi scena prima del time stamps iniziali della riga\n",
        "def adjust_subs_based_on_scenes(original_subs, scene_subs):\n",
        "    adjusted_subs = original_subs\n",
        "    for idx, sub in enumerate(adjusted_subs):\n",
        "        start_replaced = False  # Controlla se il timestamp iniziale è stato sostituito\n",
        "        for scene in reversed(scene_subs):\n",
        "            scene_end = scene.end.ordinal\n",
        "            sub_start = sub.start.ordinal\n",
        "            # Controlla se il timestamp iniziale della riga è vicino al cambio scena precedente\n",
        "            if 0 < (sub_start - scene_end) <= 250:\n",
        "                sub.start = milliseconds_to_subrip_time(scene_end)\n",
        "                start_replaced = True  # Imposta la variabile a True se il timestamp iniziale è stato sostituito\n",
        "                break\n",
        "        # Sotto-regola: se c'è una riga precedente\n",
        "        if idx > 0:\n",
        "            prev_sub = adjusted_subs[idx - 1]\n",
        "            prev_sub_end = prev_sub.end.ordinal\n",
        "            prev_sub_start = prev_sub.start.ordinal\n",
        "            if prev_sub_end > scene_end and scene_end >= prev_sub_start:\n",
        "                if start_replaced:\n",
        "                    prev_sub.end = milliseconds_to_subrip_time(scene_end - 0)\n",
        "            else:\n",
        "                # Sotto-regola: se la riga precedente non è sopra al cambio scena\n",
        "                if scene_end >= prev_sub_end:\n",
        "                    if start_replaced:\n",
        "                        sub.start = milliseconds_to_subrip_time(scene_end)\n",
        "                # Controllo: se non è stato sostituito il timestamp iniziale della riga attuale, non sostituisce il timestamp finale della riga precedente\n",
        "                if not start_replaced:\n",
        "                    prev_sub.end = milliseconds_to_subrip_time(prev_sub_end)\n",
        "    return adjusted_subs\n",
        "\n",
        "# Funzione per rilevare e sostituire il timestamp iniziale della riga se il cambio scena è entro 0,250 secondi\n",
        "def adjust_sub_start_based_on_scene_change(original_subs, scene_subs):\n",
        "    for sub in original_subs:\n",
        "        sub_start = sub.start.ordinal\n",
        "        for scene in scene_subs:\n",
        "            scene_start = scene.start.ordinal\n",
        "            # Controlla se il cambio scena si trova entro 0,250 secondi dopo il timestamp iniziale della riga attuale\n",
        "            if 0 < (scene_start - sub_start) <= 250:\n",
        "                sub.start = milliseconds_to_subrip_time(scene_start)\n",
        "                break\n",
        "    return original_subs\n",
        "\n",
        "# Funzione per aggiungere lead-in ai timestamp iniziali troppo vicini ai picchi audio\n",
        "def add_lead_in_to_peaks(subs, audio_peaks):\n",
        "    min_lead_in = 50  # Minimo lead-in in millisecondi\n",
        "    max_lead_in = 200  # Massimo lead-in in millisecondi\n",
        "    additional_lead_in = 200  # Lead-in aggiuntivo in millisecondi\n",
        "    gap_threshold = 300  # Soglia di distacco in millisecondi\n",
        "\n",
        "    for idx, sub in enumerate(subs):\n",
        "        sub_start = sub.start.ordinal\n",
        "        for peak in audio_peaks:\n",
        "            peak_time = int(peak * 1000)  # Converte i picchi in millisecondi\n",
        "            lead_in_duration = peak_time - sub_start\n",
        "            if 0 < lead_in_duration < min_lead_in:\n",
        "                # Aggiunge lead-in aggiuntivo se lead-in è troppo breve\n",
        "                sub.start = milliseconds_to_subrip_time(sub_start - additional_lead_in)\n",
        "                break\n",
        "            elif min_lead_in <= lead_in_duration <= max_lead_in:\n",
        "                # Mantiene il timestamp inalterato se il lead-in è sufficiente\n",
        "                break\n",
        "        # Sotto-regola: evita l'overlap con la riga precedente\n",
        "        if idx > 0:\n",
        "            prev_sub_end = subs[idx - 1].end.ordinal\n",
        "            if sub.start.ordinal < prev_sub_end:\n",
        "                sub.start = milliseconds_to_subrip_time(prev_sub_end + 0)\n",
        "\n",
        "        # Sotto-regola: attacca il time stamps finale della riga attuale al time stamps iniziale della riga successiva se c'è un range di 0,300 secondi\n",
        "        if idx < len(subs) - 1:\n",
        "            next_sub_start = subs[idx + 1].start.ordinal\n",
        "            if 0 < (next_sub_start - sub.end.ordinal) <= gap_threshold:\n",
        "                sub.end = milliseconds_to_subrip_time(next_sub_start)\n",
        "\n",
        "    return subs\n",
        "\n",
        "# Funzione per sostituire il timestamp finale della riga con il timestamp iniziale del cambio scena successivo\n",
        "def adjust_sub_end_based_on_next_scene_change(original_subs, scene_subs):\n",
        "    max_range = 400  # Massimo range in millisecondi\n",
        "\n",
        "    for idx, sub in enumerate(original_subs):\n",
        "        sub_end = sub.end.ordinal\n",
        "        for scene in scene_subs:\n",
        "            scene_start = scene.start.ordinal\n",
        "            # Controlla se il timestamp finale della riga è entro 0,800 secondi dal timestamp iniziale del cambio scena successivo\n",
        "            if 0 < (scene_start - sub_end) <= max_range:\n",
        "                # Sotto-regola: verifica se c'è un'altra riga tra la riga attuale e il cambio scena\n",
        "                if idx < len(original_subs) - 1 and original_subs[idx + 1].start.ordinal < scene_start:\n",
        "                    break\n",
        "                sub.end = milliseconds_to_subrip_time(scene_start)\n",
        "                break  # Esce dal loop dopo aver trovato il cambio scena entro il range\n",
        "    return original_subs\n",
        "\n",
        "# Funzione per sostituire il timestamp finale della riga con il timestamp finale del cambio scena precedente\n",
        "def adjust_sub_end_based_on_previous_scene_change(original_subs, scene_subs, audio_peaks):\n",
        "    max_range = 700  # Massimo range in millisecondi\n",
        "    extended_range = 850  # Range esteso se non ci sono picchi audio\n",
        "\n",
        "    for sub in original_subs:\n",
        "        sub_end = sub.end.ordinal\n",
        "        for scene in reversed(scene_subs):\n",
        "            scene_end = scene.end.ordinal\n",
        "            range_to_check = max_range\n",
        "\n",
        "            # Controlla se ci sono picchi audio tra sub_end e scene_end\n",
        "            peaks_in_range = any(peak for peak in audio_peaks if sub_end < peak * 1000 < scene_end)\n",
        "\n",
        "            # Se non ci sono picchi audio, estende il range massimo a 850 millisecondi\n",
        "            if not peaks_in_range:\n",
        "                range_to_check = extended_range\n",
        "\n",
        "            # Controlla se il timestamp finale della riga è entro il range determinato\n",
        "            if 0 < (sub_end - scene_end) <= range_to_check:\n",
        "                sub.end = milliseconds_to_subrip_time(scene_end)\n",
        "                break  # Esce dal loop dopo aver trovato il cambio scena entro il range\n",
        "    return original_subs\n",
        "\n",
        "# Carica i file necessari\n",
        "original_subs = pysrt.open('adjusted_Sub.srt', encoding='utf-8')\n",
        "scene_subs = pysrt.open('scene_timestamps_adjusted.srt', encoding='utf-8')\n",
        "audio_peaks = get_audio_peaks('Vocali.wav')\n",
        "\n",
        "# Funzione per aggiungere lead-in ai timestamp iniziali troppo vicini ai picchi audio\n",
        "adjusted_subs = add_lead_in_to_peaks(original_subs, audio_peaks)\n",
        "\n",
        "# Funzione per rilevare cambi scena prima del time stamps iniziali della riga\n",
        "adjusted_subs = adjust_subs_based_on_scenes(original_subs, scene_subs)\n",
        "\n",
        "# Funzione per rilevare e sostituire il timestamp iniziale della riga se il cambio scena è entro 0,250 secondi\n",
        "adjusted_subs = adjust_sub_start_based_on_scene_change(original_subs, scene_subs)\n",
        "\n",
        "# Funzione per sostituire il timestamp finale della riga con il timestamp iniziale del cambio scena successivo\n",
        "adjusted_subs = adjust_sub_end_based_on_next_scene_change(original_subs, scene_subs)\n",
        "adjusted_subs = adjust_sub_end_based_on_previous_scene_change(adjusted_subs, scene_subs, audio_peaks)\n",
        "\n",
        "# Salva il nuovo file SRT\n",
        "adjusted_subs.save('Final.srt', encoding='utf-8')\n",
        "print(\"Script completato e sottotitoli aggiornati salvati come 'adjusted_subs.srt'\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SenI8fyx6u9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Oqg9ivZjO5J6"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOOnBaZcxjpksaY58dTznKg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}